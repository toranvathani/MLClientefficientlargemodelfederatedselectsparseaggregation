{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Fg3OmMVWp_9D","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1701674596377,"user_tz":-330,"elapsed":102597,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"0d219e27-e8d2-4946-94b0-9408b5ddaa10"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting super-gradients==3.3.1\n","  Downloading super_gradients-3.3.1-py3-none-any.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (2.1.0+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (4.66.1)\n","Collecting boto3>=1.17.15 (from super-gradients==3.3.1)\n","  Downloading boto3-1.33.6-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (4.19.2)\n","Collecting Deprecated>=1.2.11 (from super-gradients==3.3.1)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: opencv-python>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (4.8.0.76)\n","Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (1.11.4)\n","Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (3.7.1)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (5.9.5)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (2.14.1)\n","Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (67.7.2)\n","Collecting coverage~=5.3.1 (from super-gradients==3.3.1)\n","  Downloading coverage-5.3.1.tar.gz (684 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.5/684.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (0.16.0+cu118)\n","Collecting sphinx~=4.0.2 (from super-gradients==3.3.1)\n","  Downloading Sphinx-4.0.3-py3-none-any.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sphinx-rtd-theme (from super-gradients==3.3.1)\n","  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchmetrics==0.8 (from super-gradients==3.3.1)\n","  Downloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hydra-core>=1.2.0 (from super-gradients==3.3.1)\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf (from super-gradients==3.3.1)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime==1.13.1 (from super-gradients==3.3.1)\n","  Downloading onnxruntime-1.13.1-cp310-cp310-manylinux_2_27_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnx==1.13.0 (from super-gradients==3.3.1)\n","  Downloading onnx-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow!=8.3,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (9.4.0)\n","Requirement already satisfied: pip-tools>=6.12.1 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (6.13.0)\n","Collecting pyparsing==2.4.5 (from super-gradients==3.3.1)\n","  Downloading pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops==0.3.2 (from super-gradients==3.3.1)\n","  Downloading einops-0.3.2-py3-none-any.whl (25 kB)\n","Collecting pycocotools==2.0.6 (from super-gradients==3.3.1)\n","  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (3.20.3)\n","Collecting treelib==1.6.1 (from super-gradients==3.3.1)\n","  Downloading treelib-1.6.1.tar.gz (24 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting termcolor==1.1.0 (from super-gradients==3.3.1)\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (23.2)\n","Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (0.42.0)\n","Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from super-gradients==3.3.1) (2.16.1)\n","Collecting stringcase>=1.2.0 (from super-gradients==3.3.1)\n","  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting numpy<=1.23 (from super-gradients==3.3.1)\n","  Downloading numpy-1.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rapidfuzz (from super-gradients==3.3.1)\n","  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting json-tricks==3.16.1 (from super-gradients==3.3.1)\n","  Downloading json_tricks-3.16.1-py2.py3-none-any.whl (27 kB)\n","Collecting onnx-simplifier<1.0,>=0.3.6 (from super-gradients==3.3.1)\n","  Downloading onnx_simplifier-0.4.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting data-gradients>=0.2.2 (from super-gradients==3.3.1)\n","  Downloading data_gradients-0.3.1-py3-none-any.whl (459 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.2/459.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx==1.13.0->super-gradients==3.3.1) (4.5.0)\n","Collecting coloredlogs (from onnxruntime==1.13.1->super-gradients==3.3.1)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->super-gradients==3.3.1) (23.5.26)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime==1.13.1->super-gradients==3.3.1) (1.12)\n","Collecting pyDeprecate==0.3.* (from torchmetrics==0.8->super-gradients==3.3.1)\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from treelib==1.6.1->super-gradients==3.3.1) (0.18.3)\n","Collecting botocore<1.34.0,>=1.33.6 (from boto3>=1.17.15->super-gradients==3.3.1)\n","  Downloading botocore-1.33.6-py3-none-any.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.17.15->super-gradients==3.3.1)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.9.0,>=0.8.2 (from boto3>=1.17.15->super-gradients==3.3.1)\n","  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.2.2->super-gradients==3.3.1) (4.0.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.2.2->super-gradients==3.3.1) (0.12.2)\n","Collecting xhtml2pdf==0.2.11 (from data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading xhtml2pdf-0.2.11.tar.gz (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from data-gradients>=0.2.2->super-gradients==3.3.1) (3.1.2)\n","Collecting imagededup (from data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading imagededup-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (176 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting arabic-reshaper>=3.0.0 (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: html5lib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (1.1)\n","Collecting pyHanko>=0.12.1 (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading pyHanko-0.21.0-py3-none-any.whl (433 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.2/433.2 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyhanko-certvalidator>=0.19.5 (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading pyhanko_certvalidator-0.26.2-py3-none-any.whl (109 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/109.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pypdf>=3.1.0 (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading pypdf-3.17.1-py3-none-any.whl (277 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.6/277.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-bidi>=0.4.2 (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n","Collecting reportlab<4,>=3.5.53 (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading reportlab-3.6.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting svglib>=1.2.1 (from xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading svglib-1.5.1.tar.gz (913 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.9/913.9 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated>=1.2.11->super-gradients==3.3.1) (1.14.1)\n","Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.2.0->super-gradients==3.3.1)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.3.1) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.3.1) (2023.11.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.3.1) (0.31.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.2.0->super-gradients==3.3.1) (0.13.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.3.1) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.3.1) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.3.1) (4.45.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.3.1) (1.4.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->super-gradients==3.3.1) (2.8.2)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf->super-gradients==3.3.1) (6.0.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier<1.0,>=0.3.6->super-gradients==3.3.1) (13.7.0)\n","Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.3.1) (1.0.3)\n","Requirement already satisfied: click>=8 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.3.1) (8.1.7)\n","Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.10/dist-packages (from pip-tools>=6.12.1->super-gradients==3.3.1) (23.1.2)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (1.0.7)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (1.0.5)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (2.0.4)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (1.1.9)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (1.0.6)\n","Collecting docutils<0.18,>=0.14 (from sphinx~=4.0.2->super-gradients==3.3.1)\n","  Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (2.2.0)\n","Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (2.13.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (0.7.13)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (1.4.1)\n","Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx~=4.0.2->super-gradients==3.3.1) (2.31.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (1.59.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (3.5.1)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->super-gradients==3.3.1) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.3.1) (3.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.3.1) (3.2.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.3.1) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->super-gradients==3.3.1) (2.1.0)\n","INFO: pip is looking at multiple versions of sphinx-rtd-theme to determine which version is compatible with other requirements. This could take a while.\n","Collecting sphinx-rtd-theme (from super-gradients==3.3.1)\n","  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->super-gradients==3.3.1)\n","  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.6->boto3>=1.17.15->super-gradients==3.3.1) (2.0.7)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients==3.3.1) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients==3.3.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients==3.3.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->super-gradients==3.3.1) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->data-gradients>=0.2.2->super-gradients==3.3.1) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients==3.3.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients==3.3.1) (3.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients==3.3.1) (2023.11.17)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.12.1->super-gradients==3.3.1) (1.0.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build->pip-tools>=6.12.1->super-gradients==3.3.1) (2.0.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.13.1->super-gradients==3.3.1)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients>=0.2.2->super-gradients==3.3.1) (1.2.2)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients>=0.2.2->super-gradients==3.3.1) (1.5.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier<1.0,>=0.3.6->super-gradients==3.3.1) (3.0.0)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn->data-gradients>=0.2.2->super-gradients==3.3.1) (1.5.3)\n","INFO: pip is looking at multiple versions of sphinxcontrib-applehelp to determine which version is compatible with other requirements. This could take a while.\n","Collecting sphinxcontrib-applehelp (from sphinx~=4.0.2->super-gradients==3.3.1)\n","  Downloading sphinxcontrib_applehelp-1.0.6-py3-none-any.whl (120 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_applehelp-1.0.5-py3-none-any.whl (120 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.6/120.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-devhelp to determine which version is compatible with other requirements. This could take a while.\n","Collecting sphinxcontrib-devhelp (from sphinx~=4.0.2->super-gradients==3.3.1)\n","  Downloading sphinxcontrib_devhelp-1.0.4-py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_devhelp-1.0.3-py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-htmlhelp to determine which version is compatible with other requirements. This could take a while.\n","Collecting sphinxcontrib-htmlhelp (from sphinx~=4.0.2->super-gradients==3.3.1)\n","  Downloading sphinxcontrib_htmlhelp-2.0.3-py3-none-any.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_htmlhelp-2.0.2-py3-none-any.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-qthelp to determine which version is compatible with other requirements. This could take a while.\n","Collecting sphinxcontrib-qthelp (from sphinx~=4.0.2->super-gradients==3.3.1)\n","  Downloading sphinxcontrib_qthelp-1.0.5-py3-none-any.whl (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_qthelp-1.0.4-py3-none-any.whl (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of sphinxcontrib-serializinghtml to determine which version is compatible with other requirements. This could take a while.\n","Collecting sphinxcontrib-serializinghtml (from sphinx~=4.0.2->super-gradients==3.3.1)\n","  Downloading sphinxcontrib_serializinghtml-1.1.8-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_serializinghtml-1.1.7-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_serializinghtml-1.1.6-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime==1.13.1->super-gradients==3.3.1) (1.3.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.0.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (0.5.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier<1.0,>=0.3.6->super-gradients==3.3.1) (0.1.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn->data-gradients>=0.2.2->super-gradients==3.3.1) (2023.3.post1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->super-gradients==3.3.1) (0.5.1)\n","Collecting asn1crypto>=1.5.1 (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting qrcode>=7.3.1 (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading qrcode-7.4.2-py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tzlocal>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (5.2)\n","Requirement already satisfied: cryptography>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (41.0.7)\n","Collecting oscrypto>=1.1.0 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading oscrypto-1.3.0-py2.py3-none-any.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uritools>=3.0.1 (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading uritools-4.0.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->super-gradients==3.3.1) (3.2.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (4.9.3)\n","Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (1.2.1)\n","Collecting cssselect2>=0.2.0 (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients>=0.2.2->super-gradients==3.3.1) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients>=0.2.2->super-gradients==3.3.1) (3.2.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (1.16.0)\n","Collecting pypng (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1)\n","  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients>=0.2.2->super-gradients==3.3.1) (2.21)\n","Building wheels for collected packages: pycocotools, termcolor, treelib, coverage, xhtml2pdf, antlr4-python3-runtime, stringcase, svglib\n","  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=377153 sha256=87223281308910e2b5ee8985239f046c154278e171f1d5fc800ea33b5392a75d\n","  Stored in directory: /root/.cache/pip/wheels/58/e6/f9/f87c8f8be098b51b616871315318329cae12cdb618f4caac93\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=49322168e806eecc015410a2e0bc3104247f63f97827ea00b8679a11e0571e10\n","  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n","  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for treelib: filename=treelib-1.6.1-py3-none-any.whl size=18369 sha256=cc6b7133a6cd962d6218f5aea35c3638421b5ccf1d6fb790ee69fb03cf03e7d9\n","  Stored in directory: /root/.cache/pip/wheels/63/72/8b/76569b82bf280a03c4e294c3b29ee2398217186369c427ed4b\n","  Building wheel for coverage (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for coverage: filename=coverage-5.3.1-cp310-cp310-linux_x86_64.whl size=235258 sha256=8ab91729c96cdc9ba1779d3bc3b971b91d45713db83674ff1204ad202393caee\n","  Stored in directory: /root/.cache/pip/wheels/e2/70/10/313be697f460d6024cfa94b7f0e22ffc1c53aab718fb4f42af\n","  Building wheel for xhtml2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for xhtml2pdf: filename=xhtml2pdf-0.2.11-py3-none-any.whl size=262646 sha256=304f9fd60a200324854d8d938bde2c0b872935ef3ea4baa0bed0238a5c2220bc\n","  Stored in directory: /root/.cache/pip/wheels/72/77/fb/e473c11c4e30a7680bf5b1b7f1d07ef04932184a2f39118e8d\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=3e620ed630704ea274af31c4a45d5e17ee45f53df9820e6614965f38f33888e0\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","  Building wheel for stringcase (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for stringcase: filename=stringcase-1.2.0-py3-none-any.whl size=3569 sha256=defc0970a021642692a21b126ec94e51141d345b868165bffb6ec586c4d8aeb5\n","  Stored in directory: /root/.cache/pip/wheels/31/ba/22/1a2d952a9ce8aa86e42fda41e2c87fdaf20e238c88bf8df013\n","  Building wheel for svglib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for svglib: filename=svglib-1.5.1-py3-none-any.whl size=30903 sha256=fe2d3bc051fa4056f473a8723b11c602724a6c5af67af560ec46a81d51982060\n","  Stored in directory: /root/.cache/pip/wheels/56/9f/90/f37f4b9dbf82987a24ae14f15586e96715cb669a4710b3b85d\n","Successfully built pycocotools termcolor treelib coverage xhtml2pdf antlr4-python3-runtime stringcase svglib\n","Installing collected packages: termcolor, stringcase, pypng, json-tricks, einops, asn1crypto, arabic-reshaper, antlr4-python3-runtime, uritools, treelib, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, reportlab, rapidfuzz, qrcode, python-bidi, pypdf, pyparsing, pyDeprecate, oscrypto, omegaconf, numpy, jmespath, humanfriendly, docutils, Deprecated, coverage, sphinx, onnx, hydra-core, cssselect2, coloredlogs, botocore, torchmetrics, svglib, sphinxcontrib-jquery, s3transfer, pyhanko-certvalidator, onnxruntime, onnx-simplifier, sphinx-rtd-theme, pyHanko, pycocotools, imagededup, boto3, xhtml2pdf, data-gradients, super-gradients\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 2.3.0\n","    Uninstalling termcolor-2.3.0:\n","      Successfully uninstalled termcolor-2.3.0\n","  Attempting uninstall: sphinxcontrib-serializinghtml\n","    Found existing installation: sphinxcontrib-serializinghtml 1.1.9\n","    Uninstalling sphinxcontrib-serializinghtml-1.1.9:\n","      Successfully uninstalled sphinxcontrib-serializinghtml-1.1.9\n","  Attempting uninstall: sphinxcontrib-qthelp\n","    Found existing installation: sphinxcontrib-qthelp 1.0.6\n","    Uninstalling sphinxcontrib-qthelp-1.0.6:\n","      Successfully uninstalled sphinxcontrib-qthelp-1.0.6\n","  Attempting uninstall: sphinxcontrib-htmlhelp\n","    Found existing installation: sphinxcontrib-htmlhelp 2.0.4\n","    Uninstalling sphinxcontrib-htmlhelp-2.0.4:\n","      Successfully uninstalled sphinxcontrib-htmlhelp-2.0.4\n","  Attempting uninstall: sphinxcontrib-devhelp\n","    Found existing installation: sphinxcontrib-devhelp 1.0.5\n","    Uninstalling sphinxcontrib-devhelp-1.0.5:\n","      Successfully uninstalled sphinxcontrib-devhelp-1.0.5\n","  Attempting uninstall: sphinxcontrib-applehelp\n","    Found existing installation: sphinxcontrib-applehelp 1.0.7\n","    Uninstalling sphinxcontrib-applehelp-1.0.7:\n","      Successfully uninstalled sphinxcontrib-applehelp-1.0.7\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.1\n","    Uninstalling pyparsing-3.1.1:\n","      Successfully uninstalled pyparsing-3.1.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18.1\n","    Uninstalling docutils-0.18.1:\n","      Successfully uninstalled docutils-0.18.1\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 5.0.2\n","    Uninstalling Sphinx-5.0.2:\n","      Successfully uninstalled Sphinx-5.0.2\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.7\n","    Uninstalling pycocotools-2.0.7:\n","      Successfully uninstalled pycocotools-2.0.7\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Deprecated-1.2.14 antlr4-python3-runtime-4.9.3 arabic-reshaper-3.0.0 asn1crypto-1.5.1 boto3-1.33.6 botocore-1.33.6 coloredlogs-15.0.1 coverage-5.3.1 cssselect2-0.7.0 data-gradients-0.3.1 docutils-0.17.1 einops-0.3.2 humanfriendly-10.0 hydra-core-1.3.2 imagededup-0.3.2 jmespath-1.0.1 json-tricks-3.16.1 numpy-1.23.0 omegaconf-2.3.0 onnx-1.13.0 onnx-simplifier-0.4.35 onnxruntime-1.13.1 oscrypto-1.3.0 pyDeprecate-0.3.2 pyHanko-0.21.0 pycocotools-2.0.6 pyhanko-certvalidator-0.26.2 pyparsing-2.4.5 pypdf-3.17.1 pypng-0.20220715.0 python-bidi-0.4.2 qrcode-7.4.2 rapidfuzz-3.5.2 reportlab-3.6.13 s3transfer-0.8.2 sphinx-4.0.3 sphinx-rtd-theme-1.3.0 sphinxcontrib-applehelp-1.0.4 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.1 sphinxcontrib-jquery-4.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 stringcase-1.2.0 super-gradients-3.3.1 svglib-1.5.1 termcolor-1.1.0 torchmetrics-0.8.0 treelib-1.6.1 uritools-4.0.2 xhtml2pdf-0.2.11\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","pydevd_plugins","pyparsing","sphinxcontrib"]}}},"metadata":{}}],"source":["!pip install super-gradients==3.3.1"]},{"cell_type":"code","source":["!pip install pytube --upgrade\n","!pip install fastapi\n","!pip install kaleido\n","!pip install python-multipart\n","!pip install uvicorn\n","!pip install pyparsing==2.4.7\n","!pip install numpy==1.23\n","!pip install protobuf==3.20.3\n","!pip install pyparsing==2.4.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RP5NDxeis3bh","executionInfo":{"status":"ok","timestamp":1701674704748,"user_tz":-330,"elapsed":95462,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"d72095b1-5f8b-4663-b667-56c4ecec7c3f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytube\n","  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pytube\n","Successfully installed pytube-15.0.0\n","Collecting fastapi\n","  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi) (3.7.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (1.10.13)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions>=4.8.0 (from fastapi)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (3.6)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi) (1.2.0)\n","Installing collected packages: typing-extensions, starlette, fastapi\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.23.0 which is incompatible.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fastapi-0.104.1 starlette-0.27.0 typing-extensions-4.8.0\n","Collecting kaleido\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: kaleido\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed kaleido-0.2.1\n","Collecting python-multipart\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: python-multipart\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed python-multipart-0.0.6\n","Collecting uvicorn\n","  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.8.0)\n","Installing collected packages: h11, uvicorn\n","Successfully installed h11-0.14.0 uvicorn-0.24.0.post1\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyparsing\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 2.4.5\n","    Uninstalling pyparsing-2.4.5:\n","      Successfully uninstalled pyparsing-2.4.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","super-gradients 3.3.1 requires pyparsing==2.4.5, but you have pyparsing 2.4.7 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pyparsing-2.4.7\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyparsing"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.23 in /usr/local/lib/python3.10/dist-packages (1.23.0)\n","Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n","Collecting pyparsing==2.4.5\n","  Using cached pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n","Installing collected packages: pyparsing\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 2.4.7\n","    Uninstalling pyparsing-2.4.7:\n","      Successfully uninstalled pyparsing-2.4.7\n","Successfully installed pyparsing-2.4.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pyparsing"]}}},"metadata":{}}]},{"cell_type":"code","source":["from super_gradients.training import Trainer\n","\n","CHECKPOINT_DIR = 'CHECKPOINT-PATH'\n","trainer = Trainer(experiment_name='yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7k10-9UAs5u7","executionInfo":{"status":"ok","timestamp":1701674757368,"user_tz":-330,"elapsed":25799,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"0257b1e8-758c-4c06-8be0-1c291747dc84"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["The console stream is logged into /root/sg_logs/console.log\n"]},{"output_type":"stream","name":"stderr","text":["[2023-12-04 07:25:43] INFO - crash_tips_setup.py - Crash tips is enabled. You can set your environment variable to CRASH_HANDLER=FALSE to disable it\n","[2023-12-04 07:25:43] WARNING - __init__.py - Failed to import pytorch_quantization\n","[2023-12-04 07:25:43] INFO - utils.py - NumExpr defaulting to 2 threads.\n","[2023-12-04 07:26:01] WARNING - calibrator.py - Failed to import pytorch_quantization\n","[2023-12-04 07:26:01] WARNING - export.py - Failed to import pytorch_quantization\n","[2023-12-04 07:26:01] WARNING - selective_quantization_utils.py - Failed to import pytorch_quantization\n"]}]},{"cell_type":"code","source":["!pip install boto3\n","!pip install deprecated\n","!pip install coverage\n","!pip install sphinx-rtd-theme\n","!pip install torchmetrics\n","!pip install hydra-core\n","!pip install omegaconf\n","!pip install onnxruntime\n","!pip install onnx\n","!pip install einops\n","!pip install treelib\n","!pip install stringcase\n","!pip install rapidfuzz\n","!pip install json-tricks\n","!pip install onnx-simplifier\n","!pip install data-gradients"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2e-JSCis72t","executionInfo":{"status":"ok","timestamp":1701674876449,"user_tz":-330,"elapsed":115725,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"79d219ff-e767-4aa1-82cf-2cc96c94a569"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.33.6)\n","Requirement already satisfied: botocore<1.34.0,>=1.33.6 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.33.6)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n","Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.8.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.6->boto3) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.6->boto3) (2.0.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.6->boto3) (1.16.0)\n","Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (1.2.14)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated) (1.14.1)\n","Requirement already satisfied: coverage in /usr/local/lib/python3.10/dist-packages (5.3.1)\n","Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.10/dist-packages (1.3.0)\n","Requirement already satisfied: sphinx<8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme) (4.0.3)\n","Requirement already satisfied: docutils<0.19 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme) (0.17.1)\n","Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /usr/local/lib/python3.10/dist-packages (from sphinx-rtd-theme) (4.1)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (1.0.4)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (1.0.2)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (2.0.1)\n","Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (1.1.5)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (1.0.3)\n","Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (3.1.2)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (2.16.1)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (2.2.0)\n","Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (2.13.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (0.7.13)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (1.4.1)\n","Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (2.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (67.7.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=1.6->sphinx-rtd-theme) (23.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx<8,>=1.6->sphinx-rtd-theme) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx<8,>=1.6->sphinx-rtd-theme) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx<8,>=1.6->sphinx-rtd-theme) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx<8,>=1.6->sphinx-rtd-theme) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx<8,>=1.6->sphinx-rtd-theme) (2023.11.17)\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.0)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n","Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.3.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics) (4.8.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.1->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.1->torchmetrics) (1.3.0)\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core) (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core) (23.2)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.1)\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf) (4.9.3)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf) (6.0.1)\n","Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.13.0)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.0)\n","Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.8.0)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.3.2)\n","Requirement already satisfied: treelib in /usr/local/lib/python3.10/dist-packages (1.6.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from treelib) (0.18.3)\n","Requirement already satisfied: stringcase in /usr/local/lib/python3.10/dist-packages (1.2.0)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (3.5.2)\n","Requirement already satisfied: json-tricks in /usr/local/lib/python3.10/dist-packages (3.16.1)\n","Requirement already satisfied: onnx-simplifier in /usr/local/lib/python3.10/dist-packages (0.4.35)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier) (1.13.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier) (13.7.0)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-simplifier) (1.23.0)\n","Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-simplifier) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-simplifier) (4.8.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnx-simplifier) (0.1.2)\n","Requirement already satisfied: data-gradients in /usr/local/lib/python3.10/dist-packages (0.3.1)\n","Requirement already satisfied: hydra-core>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (1.3.2)\n","Requirement already satisfied: omegaconf>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.3.0)\n","Requirement already satisfied: pygments>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.16.1)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (4.66.1)\n","Requirement already satisfied: platformdirs>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (4.0.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from data-gradients) (4.8.0.76)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from data-gradients) (9.4.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.14.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from data-gradients) (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.16.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from data-gradients) (1.23.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from data-gradients) (3.7.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from data-gradients) (1.11.4)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from data-gradients) (3.5.2)\n","Requirement already satisfied: coverage~=5.3.1 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (5.3.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.12.2)\n","Requirement already satisfied: xhtml2pdf==0.2.11 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.2.11)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from data-gradients) (3.1.2)\n","Requirement already satisfied: imagededup in /usr/local/lib/python3.10/dist-packages (from data-gradients) (0.3.2)\n","Requirement already satisfied: arabic-reshaper>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (3.0.0)\n","Requirement already satisfied: html5lib>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (1.1)\n","Requirement already satisfied: pyHanko>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (0.21.0)\n","Requirement already satisfied: pyhanko-certvalidator>=0.19.5 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (0.26.2)\n","Requirement already satisfied: pypdf>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (3.17.1)\n","Requirement already satisfied: python-bidi>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (0.4.2)\n","Requirement already satisfied: reportlab<4,>=3.5.53 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (3.6.13)\n","Requirement already satisfied: svglib>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from xhtml2pdf==0.2.11->data-gradients) (1.5.1)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.2.0->data-gradients) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.2.0->data-gradients) (23.2)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.2.3->data-gradients) (6.0.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients) (1.2.2)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagededup->data-gradients) (1.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->data-gradients) (2.1.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (4.45.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (2.4.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->data-gradients) (2.8.2)\n","Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn->data-gradients) (1.5.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.59.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (3.5.1)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->data-gradients) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (4.8.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (3.2.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->data-gradients) (2.1.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->data-gradients) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->data-gradients) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->data-gradients) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->data-gradients) (1.3.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.0.1->xhtml2pdf==0.2.11->data-gradients) (0.5.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn->data-gradients) (2023.3.post1)\n","Requirement already satisfied: asn1crypto>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (1.5.1)\n","Requirement already satisfied: qrcode>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (7.4.2)\n","Requirement already satisfied: tzlocal>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (5.2)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (8.1.7)\n","Requirement already satisfied: cryptography>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (41.0.7)\n","Requirement already satisfied: oscrypto>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients) (1.3.0)\n","Requirement already satisfied: uritools>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyhanko-certvalidator>=0.19.5->xhtml2pdf==0.2.11->data-gradients) (4.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->data-gradients) (2023.11.17)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients) (4.9.3)\n","Requirement already satisfied: tinycss2>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients) (1.2.1)\n","Requirement already satisfied: cssselect2>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from svglib>=1.2.1->xhtml2pdf==0.2.11->data-gradients) (0.7.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->imagededup->data-gradients) (3.2.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->data-gradients) (1.3.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (1.16.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->data-gradients) (0.5.1)\n","Requirement already satisfied: pypng in /usr/local/lib/python3.10/dist-packages (from qrcode>=7.3.1->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (0.20220715.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->data-gradients) (3.2.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=41.0.5->pyHanko>=0.12.1->xhtml2pdf==0.2.11->data-gradients) (2.21)\n"]}]},{"cell_type":"code","source":["#@test {\"skip\": true}\n","!pip install --quiet --upgrade tensorflow-federated"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ws9t8t9XsyTn","executionInfo":{"status":"ok","timestamp":1701674994521,"user_tz":-330,"elapsed":109172,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"e7e31a01-e031-4c6f-daf7-45de1a1a980c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.8/104.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.6/721.6 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.7/257.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.5/405.5 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.4/106.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for farmhashpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for jax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","fastapi 0.104.1 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n","flax 0.7.5 requires jax>=0.4.19, but you have jax 0.4.14 which is incompatible.\n","google-colab 1.0.0 requires portpicker==1.5.2, but you have portpicker 1.6.0 which is incompatible.\n","ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.20 which is incompatible.\n","onnx 1.13.0 requires protobuf<4,>=3.20.2, but you have protobuf 4.25.1 which is incompatible.\n","super-gradients 3.3.1 requires numpy<=1.23, but you have numpy 1.25.2 which is incompatible.\n","super-gradients 3.3.1 requires protobuf==3.20.3, but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"89APlnIQCvmp","executionInfo":{"status":"ok","timestamp":1701675002626,"user_tz":-330,"elapsed":2061,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["import collections\n","from collections.abc import Callable\n","import itertools\n","\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_federated as tff"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"dkDumr_6bDtY","executionInfo":{"status":"ok","timestamp":1701675005762,"user_tz":-330,"elapsed":489,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["MAX_TOKENS_SELECTED_PER_CLIENT = 6"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zyQ9xmIyvZFO","executionInfo":{"status":"ok","timestamp":1701675010783,"user_tz":-330,"elapsed":517,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["# There are some constraints on types\n","# here that will require some explicit type conversions:\n","#    - `tff.federated_select` requires int32\n","#    - `tf.SparseTensor` requires int64 indices.\n","TOKEN_DTYPE = tf.int64\n","SELECT_KEY_DTYPE = tf.int32\n","\n","# Type for counts of token occurences.\n","TOKEN_COUNT_DTYPE = tf.int32\n","\n","# A sparse feature vector can be thought of as a map\n","# from TOKEN_DTYPE to FEATURE_DTYPE.\n","# Our features are {0, 1} indicators, so we could potentially\n","# use tf.int8 as an optimization.\n","FEATURE_DTYPE = tf.int32"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"WM9Fae0PXSfa","executionInfo":{"status":"ok","timestamp":1701675015088,"user_tz":-330,"elapsed":2044,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["NUM_OOV_BUCKETS = 1\n","\n","BatchType = collections.namedtuple('BatchType', ['tokens', 'tags'])\n","\n","def build_to_ids_fn(word_vocab: list[str],\n","                    tag_vocab: list[str]) -> Callable[[tf.Tensor], tf.Tensor]:\n","  \"\"\"Constructs a function mapping examples to sequences of token indices.\"\"\"\n","  word_table_values = np.arange(len(word_vocab), dtype=np.int64)\n","  word_table = tf.lookup.StaticVocabularyTable(\n","      tf.lookup.KeyValueTensorInitializer(word_vocab, word_table_values),\n","      num_oov_buckets=NUM_OOV_BUCKETS)\n","\n","  tag_table_values = np.arange(len(tag_vocab), dtype=np.int64)\n","  tag_table = tf.lookup.StaticVocabularyTable(\n","      tf.lookup.KeyValueTensorInitializer(tag_vocab, tag_table_values),\n","      num_oov_buckets=NUM_OOV_BUCKETS)\n","\n","  def to_ids(example):\n","    \"\"\"Converts a Stack Overflow example to a bag-of-words/tags format.\"\"\"\n","    sentence = tf.strings.join([example['tokens'], example['title']],\n","                               separator=' ')\n","\n","    # We represent that label (output tags) densely.\n","    raw_tags = example['tags']\n","    tags = tf.strings.split(raw_tags, sep='|')\n","    tags = tag_table.lookup(tags)\n","    tags, _ = tf.unique(tags)\n","    tags = tf.one_hot(tags, len(tag_vocab) + NUM_OOV_BUCKETS)\n","    tags = tf.reduce_max(tags, axis=0)\n","\n","    # We represent the features as a SparseTensor of {0, 1}s.\n","    words = tf.strings.split(sentence)\n","    tokens = word_table.lookup(words)\n","    tokens, _ = tf.unique(tokens)\n","    # Note:  We could choose to use the word counts as the feature vector\n","    # instead of just {0, 1} values (see tf.unique_with_counts).\n","    tokens = tf.reshape(tokens, shape=(tf.size(tokens), 1))\n","    tokens_st = tf.SparseTensor(\n","        tokens,\n","        tf.ones(tf.size(tokens), dtype=FEATURE_DTYPE),\n","        dense_shape=(len(word_vocab) + NUM_OOV_BUCKETS,))\n","    tokens_st = tf.sparse.reorder(tokens_st)\n","\n","    return BatchType(tokens_st, tags)\n","\n","  return to_ids"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Gv9NMKgbYki9","executionInfo":{"status":"ok","timestamp":1701675019492,"user_tz":-330,"elapsed":720,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["def build_preprocess_fn(word_vocab, tag_vocab):\n","\n","  @tf.function\n","  def preprocess_fn(dataset):\n","    to_ids = build_to_ids_fn(word_vocab, tag_vocab)\n","    # We *don't* shuffle in order to make this colab deterministic for\n","    # easier testing and reproducibility.\n","    # But real-world training should use `.shuffle()`.\n","    return dataset.map(to_ids, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","  return preprocess_fn"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9gtatbx4tdPo","executionInfo":{"status":"ok","timestamp":1701675020927,"user_tz":-330,"elapsed":4,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["# Features\n","FRUIT_WORDS = ['apple', 'orange', 'pear', 'kiwi']\n","VEGETABLE_WORDS = ['carrot', 'broccoli', 'arugula', 'peas']\n","FISH_WORDS = ['trout', 'tuna', 'cod', 'salmon']\n","WORD_VOCAB = FRUIT_WORDS + VEGETABLE_WORDS + FISH_WORDS\n","\n","# Labels\n","TAG_VOCAB = ['FRUIT', 'VEGETABLE', 'FISH']"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Vr74BLPM1Mxa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701675025537,"user_tz":-330,"elapsed":2264,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"136975d5-ca3a-4ba6-a361-c13321bd13f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word vocab\n"," 0 apple\n"," 1 orange\n"," 2 pear\n"," 3 kiwi\n"," 4 carrot\n"," 5 broccoli\n"," 6 arugula\n"," 7 peas\n"," 8 trout\n"," 9 tuna\n","10 cod\n","11 salmon\n","\n","Tag vocab\n"," 0 FRUIT\n"," 1 VEGETABLE\n"," 2 FISH\n"]}],"source":["preprocess_fn = build_preprocess_fn(WORD_VOCAB, TAG_VOCAB)\n","\n","\n","def make_dataset(raw):\n","  d = tf.data.Dataset.from_tensor_slices(\n","      # Matches the StackOverflow formatting\n","      collections.OrderedDict(\n","          tokens=tf.constant([t[0] for t in raw]),\n","          tags=tf.constant([t[1] for t in raw]),\n","          title=['' for _ in raw]))\n","  d = preprocess_fn(d)\n","  return d\n","\n","\n","# 4 distinct tokens\n","CLIENT1_DATASET = make_dataset([\n","    ('apple orange apple orange', 'FRUIT'),\n","    ('carrot trout', 'VEGETABLE|FISH'),\n","    ('orange apple', 'FRUIT'),\n","    ('orange', 'ORANGE|CITRUS')  # 2 OOV tag\n","])\n","\n","# 6 distinct tokens\n","CLIENT2_DATASET = make_dataset([\n","    ('pear cod', 'FRUIT|FISH'),\n","    ('arugula peas', 'VEGETABLE'),\n","    ('kiwi pear', 'FRUIT'),\n","    ('sturgeon', 'FISH'),  # OOV word\n","    ('sturgeon bass', 'FISH')  # 2 OOV words\n","])\n","\n","# A client with all possible words & tags (13 distinct tokens).\n","# With MAX_TOKENS_SELECTED_PER_CLIENT = 6, we won't download the model\n","# slices for all tokens that occur on this client.\n","CLIENT3_DATASET = make_dataset([\n","    (' '.join(WORD_VOCAB + ['oovword']), '|'.join(TAG_VOCAB)),\n","    # Mathe the OOV token and 'salmon' occur in the largest number\n","    # of examples on this client:\n","    ('salmon oovword', 'FISH|OOVTAG')\n","])\n","\n","print('Word vocab')\n","for i, word in enumerate(WORD_VOCAB):\n","  print(f'{i:2d} {word}')\n","\n","print('\\nTag vocab')\n","for i, tag in enumerate(TAG_VOCAB):\n","  print(f'{i:2d} {tag}')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vBULpAepxloO","executionInfo":{"status":"ok","timestamp":1701675029212,"user_tz":-330,"elapsed":4,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["NUM_WORDS = len(WORD_VOCAB)\n","NUM_TAGS = len(TAG_VOCAB)\n","\n","WORD_VOCAB_SIZE = NUM_WORDS + NUM_OOV_BUCKETS\n","TAG_VOCAB_SIZE = NUM_TAGS + NUM_OOV_BUCKETS"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"4uxRQAYdJISP","executionInfo":{"status":"ok","timestamp":1701675033147,"user_tz":-330,"elapsed":659,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["batched_dataset1 = CLIENT1_DATASET.batch(2)\n","batched_dataset2 = CLIENT2_DATASET.batch(3)\n","batched_dataset3 = CLIENT3_DATASET.batch(2)\n","\n","batch1 = next(iter(batched_dataset1))\n","batch2 = next(iter(batched_dataset2))\n","batch3 = next(iter(batched_dataset3))"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"RTtIkxCKao2Y","executionInfo":{"status":"ok","timestamp":1701675036071,"user_tz":-330,"elapsed":4,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["def create_logistic_model(word_vocab_size: int, vocab_tags_size: int):\n","\n","  model = tf.keras.models.Sequential([\n","      tf.keras.layers.InputLayer(input_shape=(word_vocab_size,), sparse=True),\n","      tf.keras.layers.Dense(\n","          vocab_tags_size,\n","          activation='sigmoid',\n","          kernel_initializer=tf.keras.initializers.zeros,\n","          # For simplicity, don't use a bias vector; this means the model\n","          # is a single tensor, and we only need sparse aggregation of\n","          # the per-token slices of the model. Generalizing to also handle\n","          # other model weights that are fully updated\n","          # (non-dense broadcast and aggregate) would be a good exercise.\n","          use_bias=False),\n","  ])\n","\n","  return model"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"cGQOnvbfa3w4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701675040480,"user_tz":-330,"elapsed":1235,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"9d5e9b6e-0b65-4938-a10e-9068484b9b55"},"outputs":[{"output_type":"stream","name":"stdout","text":["\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 1s 634ms/step\n","[[0.5 0.5 0.5 0.5]\n"," [0.5 0.5 0.5 0.5]]\n"]}],"source":["model = create_logistic_model(WORD_VOCAB_SIZE, TAG_VOCAB_SIZE)\n","p = model.predict(batch1.tokens)\n","print(p)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"jn3lB84WgRgV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701675048273,"user_tz":-330,"elapsed":2778,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"69297d1c-2e64-42da-e56d-b9e4976a6bd9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.69295334815979"]},"metadata":{},"execution_count":16}],"source":["model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.001),\n","              loss=tf.keras.losses.BinaryCrossentropy())\n","model.train_on_batch(batch1.tokens, batch1.tags)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"GRr0ip0ja31O","executionInfo":{"status":"ok","timestamp":1701675050925,"user_tz":-330,"elapsed":721,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["@tf.function\n","def token_count_fn(token_counts, batch):\n","  \"\"\"Adds counts from `batch` to the running `token_counts` sum.\"\"\"\n","  # Sum across the batch dimension.\n","  flat_tokens = tf.sparse.reduce_sum(\n","      batch.tokens, axis=0, output_is_sparse=True)\n","  flat_tokens = tf.cast(flat_tokens, dtype=TOKEN_COUNT_DTYPE)\n","  return tf.sparse.add(token_counts, flat_tokens)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"LTZdZZhFgeYz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701675053130,"user_tz":-330,"elapsed":3,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"5bc803f4-b966-4b4a-e58d-377d9ca2990c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tokens: [0 1 4 8]\n","counts: [2 3 1 1]\n"]}],"source":["# Simple tests\n","# Create the initial zero token counts using empty tensors.\n","initial_token_counts = tf.SparseTensor(\n","    indices=tf.zeros(shape=(0, 1), dtype=TOKEN_DTYPE),\n","    values=tf.zeros(shape=(0,), dtype=TOKEN_COUNT_DTYPE),\n","    dense_shape=(WORD_VOCAB_SIZE,))\n","\n","client_token_counts = batched_dataset1.reduce(initial_token_counts,\n","                                              token_count_fn)\n","tokens = tf.reshape(client_token_counts.indices, (-1,)).numpy()\n","print('tokens:', tokens)\n","np.testing.assert_array_equal(tokens, [0, 1, 4, 8])\n","# The count is the number of *examples* in which the token/word\n","# occurs, not the total number of occurences, since we still featurize\n","# multiple occurences in the same example as a \"1\".\n","counts = client_token_counts.values.numpy()\n","print('counts:', counts)\n","np.testing.assert_array_equal(counts, [2, 3, 1, 1])"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"45YOfL8fh5K8","executionInfo":{"status":"ok","timestamp":1701675056345,"user_tz":-330,"elapsed":503,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["@tf.function\n","def keys_for_client(client_dataset, max_tokens_per_client):\n","  \"\"\"Computes a set of max_tokens_per_client keys.\"\"\"\n","  initial_token_counts = tf.SparseTensor(\n","      indices=tf.zeros((0, 1), dtype=TOKEN_DTYPE),\n","      values=tf.zeros((0,), dtype=TOKEN_COUNT_DTYPE),\n","      dense_shape=(WORD_VOCAB_SIZE,))\n","  client_token_counts = client_dataset.reduce(initial_token_counts,\n","                                              token_count_fn)\n","  # Find the most-frequently occuring tokens\n","  tokens = tf.reshape(client_token_counts.indices, shape=(-1,))\n","  counts = client_token_counts.values\n","  perm = tf.argsort(counts, direction='DESCENDING')\n","  tokens = tf.gather(tokens, perm)\n","  counts = tf.gather(counts, perm)\n","  num_raw_tokens = tf.shape(tokens)[0]\n","  actual_num_tokens = tf.minimum(max_tokens_per_client, num_raw_tokens)\n","  selected_tokens = tokens[:actual_num_tokens]\n","  paddings = [[0, max_tokens_per_client - tf.shape(selected_tokens)[0]]]\n","  padded_tokens = tf.pad(selected_tokens, paddings=paddings)\n","  # Make sure the type is statically determined\n","  padded_tokens = tf.reshape(padded_tokens, shape=(max_tokens_per_client,))\n","\n","  # We will pass these tokens as keys into `federated_select`, which\n","  # requires SELECT_KEY_DTYPE=tf.int32 keys.\n","  padded_tokens = tf.cast(padded_tokens, dtype=SELECT_KEY_DTYPE)\n","  return padded_tokens, actual_num_tokens"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"bTyJVDqkjGyG","executionInfo":{"status":"ok","timestamp":1701675060445,"user_tz":-330,"elapsed":1963,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["# Simple test\n","\n","# Case 1: actual_num_tokens > max_tokens_per_client\n","selected_tokens, actual_num_tokens = keys_for_client(batched_dataset1, 3)\n","assert tf.size(selected_tokens) == 3\n","assert actual_num_tokens == 3\n","\n","# Case 2: actual_num_tokens < max_tokens_per_client\n","selected_tokens, actual_num_tokens = keys_for_client(batched_dataset1, 10)\n","assert tf.size(selected_tokens) == 10\n","assert actual_num_tokens == 4"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"UG3uLlqJohXg","executionInfo":{"status":"ok","timestamp":1701675063005,"user_tz":-330,"elapsed":413,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["@tf.function\n","def map_to_local_token_ids(client_data, client_keys):\n","  global_to_local = tf.lookup.StaticHashTable(\n","      # Note int32 -> int64 maps are not supported\n","      tf.lookup.KeyValueTensorInitializer(\n","          keys=tf.cast(client_keys, dtype=TOKEN_DTYPE),\n","          # Note we need to use tf.shape, not the static\n","          # shape client_keys.shape[0]\n","          values=tf.range(0, limit=tf.shape(client_keys)[0],\n","                          dtype=TOKEN_DTYPE)),\n","      # We use -1 for tokens that were not selected, which can occur for clients\n","      # with more than MAX_TOKENS_SELECTED_PER_CLIENT distinct tokens.\n","      # We will simply remove these invalid indices from the batch below.\n","      default_value=-1)\n","\n","  def to_local_ids(sparse_tokens):\n","    indices_t = tf.transpose(sparse_tokens.indices)\n","    batch_indices = indices_t[0]  # First column\n","    tokens = indices_t[1]  # Second column\n","    tokens = tf.map_fn(\n","        lambda global_token_id: global_to_local.lookup(global_token_id), tokens)\n","    # Remove tokens that aren't actually available (looked up as -1):\n","    available_tokens = tokens >= 0\n","    tokens = tokens[available_tokens]\n","    batch_indices = batch_indices[available_tokens]\n","\n","    updated_indices = tf.transpose(\n","        tf.concat([[batch_indices], [tokens]], axis=0))\n","    st = tf.sparse.SparseTensor(\n","        updated_indices,\n","        tf.ones(tf.size(tokens), dtype=FEATURE_DTYPE),\n","        # Each client has at most MAX_TOKENS_SELECTED_PER_CLIENT distinct tokens.\n","        dense_shape=[sparse_tokens.dense_shape[0], MAX_TOKENS_SELECTED_PER_CLIENT])\n","    st = tf.sparse.reorder(st)\n","    return st\n","\n","  return client_data.map(lambda b: BatchType(to_local_ids(b.tokens), b.tags))"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"y_Cn60NIBUWf","executionInfo":{"status":"ok","timestamp":1701675066591,"user_tz":-330,"elapsed":822,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["# Simple test\n","client_keys, actual_num_tokens = keys_for_client(\n","    batched_dataset3, MAX_TOKENS_SELECTED_PER_CLIENT)\n","client_keys = client_keys[:actual_num_tokens]\n","\n","d = map_to_local_token_ids(batched_dataset3, client_keys)\n","batch  = next(iter(d))\n","all_tokens = tf.gather(batch.tokens.indices, indices=1, axis=1)\n","# Confirm we have local indices in the range [0, MAX):\n","assert tf.math.reduce_max(all_tokens) < MAX_TOKENS_SELECTED_PER_CLIENT\n","assert tf.math.reduce_max(all_tokens) >= 0"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"gFpC_nFjgbtI","executionInfo":{"status":"ok","timestamp":1701675069357,"user_tz":-330,"elapsed":613,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["@tf.function\n","def slices_dataset_to_tensor(slices_dataset):\n","  \"\"\"Convert a dataset of slices to a tensor.\"\"\"\n","  # Use batching to gather all of the slices into a single tensor.\n","  d = slices_dataset.batch(MAX_TOKENS_SELECTED_PER_CLIENT,\n","                           drop_remainder=False)\n","  iter_d = iter(d)\n","  tensor = next(iter_d)\n","  # Make sure we have consumed everything\n","  opt = iter_d.get_next_as_optional()\n","  tf.Assert(tf.logical_not(opt.has_value()), data=[''], name='CHECK_EMPTY')\n","  return tensor"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"xX0gtz5Ylvqf","executionInfo":{"status":"ok","timestamp":1701675071641,"user_tz":-330,"elapsed":2,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["# Simple test\n","weights = np.random.random(\n","    size=(MAX_TOKENS_SELECTED_PER_CLIENT, TAG_VOCAB_SIZE)).astype(np.float32)\n","model_slices_as_dataset = tf.data.Dataset.from_tensor_slices(weights)\n","weights2 = slices_dataset_to_tensor(model_slices_as_dataset)\n","np.testing.assert_array_equal(weights, weights2)"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"aG66d8UR_9Gm","executionInfo":{"status":"ok","timestamp":1701675074061,"user_tz":-330,"elapsed":718,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["@tf.function\n","def client_train_fn(model, client_optimizer,\n","                    model_slices_as_dataset, client_data,\n","                    client_keys, actual_num_tokens):\n","\n","  initial_model_weights = slices_dataset_to_tensor(model_slices_as_dataset)\n","  assert len(model.trainable_variables) == 1\n","  model.trainable_variables[0].assign(initial_model_weights)\n","\n","  # Only keep the \"real\" (unpadded) keys.\n","  client_keys = client_keys[:actual_num_tokens]\n","\n","  client_data = map_to_local_token_ids(client_data, client_keys)\n","\n","  loss_fn = tf.keras.losses.BinaryCrossentropy()\n","  for features, labels in client_data:\n","    with tf.GradientTape() as tape:\n","      predictions = model(features)\n","      loss = loss_fn(labels, predictions)\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    client_optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","  model_weights_delta = model.trainable_weights[0] - initial_model_weights\n","  model_weights_delta = tf.slice(model_weights_delta, begin=[0, 0],\n","                           size=[actual_num_tokens, -1])\n","  return client_keys, model_weights_delta"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"3XOe0thb2TQr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701675077778,"user_tz":-330,"elapsed":1974,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"34a1dfe9-63cf-4d80-bd21-98bcdfb179c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[ 6.25e-05  6.25e-05  6.25e-05 -6.25e-05]\n"," [ 0.00e+00  0.00e+00  1.25e-04  0.00e+00]\n"," [ 6.25e-05  6.25e-05  6.25e-05 -6.25e-05]\n"," [ 6.25e-05  6.25e-05  6.25e-05 -6.25e-05]\n"," [ 6.25e-05  6.25e-05  6.25e-05 -6.25e-05]\n"," [ 6.25e-05  6.25e-05  6.25e-05 -6.25e-05]], shape=(6, 4), dtype=float32)\n"]}],"source":["# Simple test\n","# Note if you execute this cell a second time, you need to also re-execute\n","# the preceeding cell to avoid \"tf.function-decorated function tried to\n","# create variables on non-first call\" errors.\n","on_device_model = create_logistic_model(MAX_TOKENS_SELECTED_PER_CLIENT,\n","                                        TAG_VOCAB_SIZE)\n","client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n","client_keys, actual_num_tokens = keys_for_client(\n","    batched_dataset2, MAX_TOKENS_SELECTED_PER_CLIENT)\n","\n","model_slices_as_dataset = tf.data.Dataset.from_tensor_slices(\n","    np.zeros((MAX_TOKENS_SELECTED_PER_CLIENT, TAG_VOCAB_SIZE),\n","             dtype=np.float32))\n","\n","keys, delta = client_train_fn(\n","    on_device_model,\n","    client_optimizer,\n","    model_slices_as_dataset,\n","    client_data=batched_dataset3,\n","    client_keys=client_keys,\n","    actual_num_tokens=actual_num_tokens)\n","\n","print(delta)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"EIG_XYd2OYeO","executionInfo":{"status":"ok","timestamp":1701675082561,"user_tz":-330,"elapsed":605,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["def federated_indexed_slices_sum(slice_indices, slice_values, dense_shape):\n","  \"\"\"\n","  Sums IndexedSlices@CLIENTS to a dense @SERVER Tensor.\n","\n","  Intermediate aggregation is performed by converting to a dense representation,\n","  which may not be suitable for all applications.\n","\n","  Args:\n","    slice_indices: An IndexedSlices.indices tensor @CLIENTS.\n","    slice_values: An IndexedSlices.values tensor @CLIENTS.\n","    dense_shape: A statically known dense shape.\n","\n","  Returns:\n","    A dense tensor placed @SERVER representing the sum of the client's\n","    IndexedSclies.\n","  \"\"\"\n","  slices_dtype = slice_values.type_signature.member.dtype\n","  zero = tff.tf_computation(\n","      lambda: tf.zeros(dense_shape, dtype=slices_dtype))()\n","\n","  @tf.function\n","  def accumulate_slices(dense, client_value):\n","    indices, slices = client_value\n","    # There is no built-in way to add `IndexedSlices`, but\n","    # tf.convert_to_tensor is a quick way to convert to a dense representation\n","    # so we can add them.\n","    return dense + tf.convert_to_tensor(\n","        tf.IndexedSlices(slices, indices, dense_shape))\n","\n","\n","  return tff.federated_aggregate(\n","      (slice_indices, slice_values),\n","      zero=zero,\n","      accumulate=tff.tf_computation(accumulate_slices),\n","      merge=tff.tf_computation(lambda d1, d2: tf.add(d1, d2, name='merge')),\n","      report=tff.tf_computation(lambda d: d))\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"i_FIvwj3UIAq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701675085539,"user_tz":-330,"elapsed":4,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"ac6da5f2-a24e-4478-9e56-1e4a42e5ffe7"},"outputs":[{"output_type":"stream","name":"stdout","text":["({<int64[?],float32[?,2]>}@CLIENTS -> float32[6,2]@SERVER)\n"]}],"source":["dense_shape = (6, 2)\n","indices_type = tff.TensorType(tf.int64, (None,))\n","values_type = tff.TensorType(tf.float32, (None, 2))\n","client_slice_type = tff.type_at_clients(\n","    (indices_type, values_type))\n","\n","@tff.federated_computation(client_slice_type)\n","def test_sum_indexed_slices(indices_values_at_client):\n","  indices, values = indices_values_at_client\n","  return federated_indexed_slices_sum(indices, values, dense_shape)\n","\n","print(test_sum_indexed_slices.type_signature)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"dulcCZg2S_9f","executionInfo":{"status":"ok","timestamp":1701675089022,"user_tz":-330,"elapsed":1236,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["x = tf.IndexedSlices(\n","    values=np.array([[2., 2.1], [0., 0.1], [1., 1.1], [5., 5.1]],\n","                    dtype=np.float32),\n","    indices=[2, 0, 1, 5],\n","    dense_shape=dense_shape)\n","y = tf.IndexedSlices(\n","    values=np.array([[0., 0.3], [3.1, 3.2]], dtype=np.float32),\n","    indices=[1, 3],\n","    dense_shape=dense_shape)\n","\n","# Sum one.\n","result = test_sum_indexed_slices([(x.indices, x.values)])\n","np.testing.assert_array_equal(tf.convert_to_tensor(x), result)\n","\n","# Sum two.\n","expected = [[0., 0.1], [1., 1.4], [2., 2.1], [3.1, 3.2], [0., 0.], [5., 5.1]]\n","result = test_sum_indexed_slices([(x.indices, x.values), (y.indices, y.values)])\n","np.testing.assert_array_almost_equal(expected, result)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"9yRpGJr_i3XK","executionInfo":{"status":"ok","timestamp":1701675090444,"user_tz":-330,"elapsed":2,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["DENSE_MODEL_SHAPE = (WORD_VOCAB_SIZE, TAG_VOCAB_SIZE)\n","client_data_type = tff.SequenceType(batched_dataset1.element_spec)\n","model_type = tff.TensorType(tf.float32, shape=DENSE_MODEL_SHAPE)"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"gGgKTpnscdZI","executionInfo":{"status":"ok","timestamp":1701675092598,"user_tz":-330,"elapsed":3,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["@tff.tf_computation\n","def server_update(current_model_weights, update_sum, num_clients):\n","  average_update = update_sum / num_clients\n","  return current_model_weights + average_update"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"soFQAmktUtYp","executionInfo":{"status":"ok","timestamp":1701675094437,"user_tz":-330,"elapsed":2,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["# Function to select slices from the model weights in federated_select:\n","select_fn = tff.tf_computation(\n","    lambda model_weights, index: tf.gather(model_weights, index))\n","\n","\n","# We need to wrap `client_train_fn` as a `tff.tf_computation`, making\n","# sure we do any operations that might construct `tf.Variable`s outside\n","# of the `tf.function` we are wrapping.\n","@tff.tf_computation\n","def client_train_fn_tff(model_slices_as_dataset, client_data, client_keys,\n","                        actual_num_tokens):\n","  # Note this is amaller than the global model, using\n","  # MAX_TOKENS_SELECTED_PER_CLIENT which is much smaller than WORD_VOCAB_SIZE.\n","  # We would like a model of size `actual_num_tokens`, but we\n","  # can't build the model dynamically, so we will slice off the padded\n","  # weights at the end.\n","  client_model = create_logistic_model(MAX_TOKENS_SELECTED_PER_CLIENT,\n","                                       TAG_VOCAB_SIZE)\n","  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n","  return client_train_fn(client_model, client_optimizer,\n","                         model_slices_as_dataset, client_data, client_keys,\n","                         actual_num_tokens)\n","\n","@tff.tf_computation\n","def keys_for_client_tff(client_data):\n","  return keys_for_client(client_data, MAX_TOKENS_SELECTED_PER_CLIENT)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"LM_2mzkgBOjl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701675098023,"user_tz":-330,"elapsed":1126,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"00700d60-fc3d-4b1e-c6ca-8201d0797c03"},"outputs":[{"output_type":"stream","name":"stdout","text":["(<server_model=float32[13,4]@SERVER,client_data={<tokens=<indices=int64[?,2],values=int32[?],dense_shape=int64[2]>,tags=float32[?,4]>*}@CLIENTS> -> float32[13,4]@SERVER)\n"]}],"source":["@tff.federated_computation(\n","    tff.type_at_server(model_type), tff.type_at_clients(client_data_type))\n","def sparse_model_update(server_model, client_data):\n","  max_tokens = tff.federated_value(MAX_TOKENS_SELECTED_PER_CLIENT, tff.SERVER)\n","  keys_at_clients, actual_num_tokens = tff.federated_map(\n","      keys_for_client_tff, client_data)\n","\n","  model_slices = tff.federated_select(keys_at_clients, max_tokens, server_model,\n","                                      select_fn)\n","\n","  update_keys, update_slices = tff.federated_map(\n","      client_train_fn_tff,\n","      (model_slices, client_data, keys_at_clients, actual_num_tokens))\n","\n","  dense_update_sum = federated_indexed_slices_sum(update_keys, update_slices,\n","                                                  DENSE_MODEL_SHAPE)\n","  num_clients = tff.federated_sum(tff.federated_value(1.0, tff.CLIENTS))\n","\n","  updated_server_model = tff.federated_map(\n","      server_update, (server_model, dense_update_sum, num_clients))\n","\n","  return updated_server_model\n","\n","\n","print(sparse_model_update.type_signature)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"Rn_V-E3FdrLO","executionInfo":{"status":"ok","timestamp":1701675101510,"user_tz":-330,"elapsed":710,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}}},"outputs":[],"source":["server_model = create_logistic_model(WORD_VOCAB_SIZE, TAG_VOCAB_SIZE)\n","server_model.compile(  # Compile to make evaluation easy.\n","    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.0),  # Unused\n","    loss=tf.keras.losses.BinaryCrossentropy(),\n","    metrics=[\n","      tf.keras.metrics.Precision(name='precision'),\n","      tf.keras.metrics.AUC(name='auc'),\n","      tf.keras.metrics.Recall(top_k=2, name='recall_at_2'),\n","  ])\n","\n","def evaluate(model, dataset, name):\n","  metrics = model.evaluate(dataset, verbose=0)\n","  metrics_str = ', '.join([f'{k}={v:.2f}' for k, v in\n","                          (zip(server_model.metrics_names, metrics))])\n","  print(f'{name}: {metrics_str}')"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"bw7S9PmfZ3Bw","colab":{"base_uri":"https://localhost:8080/","height":546},"executionInfo":{"status":"error","timestamp":1701675223531,"user_tz":-330,"elapsed":1267,"user":{"displayName":"Toran Athani","userId":"17295137007520521741"}},"outputId":"c0e0ae3e-3668-4943-a283-2d79a519ddea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Before training\n","Client 1: loss=0.69, precision=0.00, auc=0.50, recall_at_2=0.60\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-df099053b077>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mclients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcohort_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training on clients'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   model_weights = sparse_model_update(\n\u001b[0m\u001b[1;32m     16\u001b[0m       model_weights, [client_datasets[i] for i in clients])\n\u001b[1;32m     17\u001b[0m \u001b[0mserver_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/computation/computation_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/execution_contexts/sync_execution_context.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     return self._async_runner.run_coro_and_return_result(\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/async_utils.py\u001b[0m in \u001b[0;36mrun_coro_and_return_result\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;34m\"\"\"Runs coroutine in the managed event loop, returning the result.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_coroutine_threadsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawait_coro_and_return_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/retrying.py\u001b[0m in \u001b[0;36mretry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mretry_on_exception_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m           \u001b[0mretry_wait_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_max_ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_wait_ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwait_multiplier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m           \u001b[0;31m# asyncio.sleep takes arguments in seconds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/retrying.py\u001b[0m in \u001b[0;36mretry_coro_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mretry_on_result_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mretry_wait_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_max_ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_wait_ms\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwait_multiplier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, comp, arg)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m           arg = await tracing.wrap_coroutine_in_current_trace_context(\n\u001b[0m\u001b[1;32m    222\u001b[0m               \u001b[0m_ingest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/tracing.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m()\u001b[0m\n\u001b[1;32m    404\u001b[0m   \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_with_span_yields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_span_yields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py\u001b[0m in \u001b[0;36m_ingest\u001b[0;34m(executor, val, type_spec)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_elem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_elem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mingested\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ingest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mingested\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mingested\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     return await executor.create_struct(\n\u001b[1;32m    107\u001b[0m         structure.Struct(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/execution_contexts/async_execution_context.py\u001b[0m in \u001b[0;36m_ingest\u001b[0;34m(executor, val, type_spec)\u001b[0m\n\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    111\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/tracing.py\u001b[0m in \u001b[0;36masync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0;31m# and passing it back to the span generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/remote_executor.py\u001b[0m in \u001b[0;36mcreate_value\u001b[0;34m(self, value, type_spec)\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_value_stream_structs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mvalue_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     create_value_request = executor_pb2.CreateValueRequest(\n\u001b[1;32m    232\u001b[0m         \u001b[0mexecutor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/tracing.py\u001b[0m in \u001b[0;36msync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/remote_executor.py\u001b[0m in \u001b[0;36mserialize_value\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtracing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mserialize_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue_serialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     if self._stream_structs and isinstance(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/tracing.py\u001b[0m in \u001b[0;36msync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/value_serialization.py\u001b[0m in \u001b[0;36mserialize_value\u001b[0;34m(value, type_spec)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_serialize_struct_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFederatedType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_serialize_federated_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/tracing.py\u001b[0m in \u001b[0;36msync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/value_serialization.py\u001b[0m in \u001b[0;36m_serialize_federated_value\u001b[0;34m(federated_value, type_spec)\u001b[0m\n\u001b[1;32m    315\u001b[0m   \u001b[0mvalue_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0mfederated_value_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_assignable_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0mvalue_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfederated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederated_value_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/tracing.py\u001b[0m in \u001b[0;36msync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/value_serialization.py\u001b[0m in \u001b[0;36mserialize_value\u001b[0;34m(value, type_spec)\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_serialize_tensor_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequenceType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_serialize_sequence_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_serialize_struct_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/common_libs/tracing.py\u001b[0m in \u001b[0;36msync_trace\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/value_serialization.py\u001b[0m in \u001b[0;36m_serialize_sequence_value\u001b[0;34m(value, type_spec)\u001b[0m\n\u001b[1;32m    254\u001b[0m     )\n\u001b[1;32m    255\u001b[0m   \u001b[0melement_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m   \u001b[0m_check_container_compat_with_tf_nest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m   \u001b[0mvalue_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequenceType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtype_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_assignable_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/value_serialization.py\u001b[0m in \u001b[0;36m_check_container_compat_with_tf_nest\u001b[0;34m(type_spec)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtype_to_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m   type_transformations.transform_type_postorder(\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0mtype_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_ordereddict_container_for_struct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/types/type_transformations.py\u001b[0m in \u001b[0;36mtransform_type_postorder\u001b[0;34m(type_signature, transform_fn)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0melements_mutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m       transformed_element, element_mutated = transform_type_postorder(\n\u001b[0m\u001b[1;32m    103\u001b[0m           \u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/types/type_transformations.py\u001b[0m in \u001b[0;36mtransform_type_postorder\u001b[0;34m(type_signature, transform_fn)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mtype_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStructType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mtype_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_signature_mutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtype_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_signature_mutated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melements_mutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   elif isinstance(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_federated/python/core/impl/executors/value_serialization.py\u001b[0m in \u001b[0;36m_check_ordereddict_container_for_struct\u001b[0;34m(type_to_check)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mtype_to_check\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_container\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     ):\n\u001b[0;32m--> 207\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m    208\u001b[0m           \u001b[0;34m'Attempted to serialize a dataset yielding named '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m           \u001b[0;34m'elements in non-sorted sequence order with '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Attempted to serialize a dataset yielding named elements in non-sorted sequence order with non-OrderedDict container (type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>). This is an ambiguous operation; `tf.nest` behaves in a manner which depends on the Python type of this container, so coercing the dataset reconstructed from the resulting Value proto depends on assuming a single Python type here. Please prefer to use `collections.OrderedDict` containers for the elements your dataset yields."]},{"output_type":"stream","name":"stdout","text":["Client 2: loss=0.69, precision=0.00, auc=0.50, recall_at_2=0.50\n","Client 3: loss=0.69, precision=0.00, auc=0.50, recall_at_2=0.40\n","Training on clients [0 2 1]\n"]}],"source":["print('Before training')\n","evaluate(server_model, batched_dataset1, 'Client 1')\n","evaluate(server_model, batched_dataset2, 'Client 2')\n","evaluate(server_model, batched_dataset3, 'Client 3')\n","\n","model_weights = server_model.trainable_weights[0]\n","\n","client_datasets = [batched_dataset1, batched_dataset2, batched_dataset3]\n","for _ in range(10):  # Run 10 rounds of FedAvg\n","  # We train on 1, 2, or 3 clients per round, selecting\n","  # randomly.\n","  cohort_size = np.random.randint(1, 4)\n","  clients = np.random.choice([0, 1, 2], cohort_size, replace=False)\n","  print('Training on clients', clients)\n","  model_weights = sparse_model_update(\n","      model_weights, [client_datasets[i] for i in clients])\n","server_model.set_weights([model_weights])\n","\n","print('After training')\n","evaluate(server_model, batched_dataset1, 'Client 1')\n","evaluate(server_model, batched_dataset2, 'Client 2')\n","evaluate(server_model, batched_dataset3, 'Client 3')"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}